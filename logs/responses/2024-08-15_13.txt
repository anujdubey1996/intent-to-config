
Here are some examples of Kubernetes deployment configurations based on intent:

Intent: Unknown Intent
Configuration:
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: neptune-10ab
  name: neptune-10ab
  namespace: neptune
spec:
  replicas: 3
  selector:
    matchLabels:
      app: neptune-10ab
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: neptune-10ab
    spec:
      serviceAccountName: neptune-sa-v2
      containers:
      - image: httpd:2.4-alpine
        name: neptune-pod-10ab
        resources:
          requests:
            memory: 20Mi
          limits:
            memory: 50Mi

status: {}


Intent: Define a Kubernetes deployment for a container running the lalyos/12factor image with environment variables sourced from a secret.
Configuration:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: geolocationdb
  labels:
    app: geolocationdb
spec:
  selector:
    matchLabels:
      app: geolocationdb
  replicas: 1
  template:
    metadata:
      labels:
        app: geolocationdb
    spec:
      containers:
      - name: geolocationdb
        image: vprofile/vprofiledb:V1
        args:
         - "--ignore-db-dir=lost+found"
        volumeMounts:
        - mountPath: /var/lib/mysql
          name: geolo-db-data
        ports:
        - name: geolo-port
          containerPort: 3306
        env:
         - name: MYSQL_ROOT_PASSWORD
           valueFrom:
             secretKeyRef:
               name: app-secret
               key: db-pass
      nodeSelector:
        zone: us-east-1a
      volumes:
        - name: geolo-db-data
          # This AWS EBS volume must already exist.
          awsElasticBlockStore:
             volumeID: vol-0343110a53e1a3eaf
             fsType: ext4


Intent: Deploy a containerized application with specific environment variables. The deployment configuration specifies a single container using an image built from a Dockerfile and sets various environment variables.
Configuration:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dp
  namespace: own
spec: 
  replicas: 2
  strategy: 
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  minReadySeconds: 30
  selector:
    matchLabels:
      app: java
  template:
    metadata: 
     name: tmp
     labels:
       app: java
    spec:
      containers:
      - name: con
        image: 637423476845.dkr.ecr.ap-south-1.amazonaws.com/ecs:test
        ports:
        - containerPort: 8080



Intent: Create a Kubernetes Deployment for a Redis instance with a single replica. The deployment configures resource requests and limits for the Redis container and exposes the default Redis port
Configuration:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: currencyservice
spec:
  selector:
    matchLabels:
      app: currencyservice
  template:
    metadata:
      labels:
        app: currencyservice
    spec:
      serviceAccountName: default
      terminationGracePeriodSeconds: 5
      containers:
        - name: server
          image: gcr.io/google-samples/microservices-demo/currencyservice:v0.3.6
          ports:
            - name: grpc
              containerPort: 7000
          env:
            - name: PORT
              value: "7000"
            - name: DISABLE_TRACING
              value: "1"
            - name: DISABLE_PROFILER
              value: "1"
            - name: DISABLE_DEBUGGER
              value: "1"
          readinessProbe:
            exec:
              command: ["/bin/grpc_health_probe", "-addr=:7000"]
          livenessProbe:
            exec:
              command: ["/bin/grpc_health_probe", "-addr=:7000"]
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 128Mi


Intent: Deploy the cert-controller in a Kubernetes cluster when the certController is to be created and the certManager is not enabled for the webhook
Configuration:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stash-demo
  namespace: demo
  labels:
    app: stash-demo
  # This annotations indicates that data should be recovered on each restart of the workload
  annotations:
    stash.appscode.com/restorepolicy: "OnRestart"
    stash.appscode.com/repository: "demo-backup-repo"
    stash.appscode.com/directories: "[/source/data]"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: stash-demo
  template:
    metadata:
      labels:
        app: stash-demo
      name: busybox
    spec:
      containers:
      - args:
        - sleep
        - "3600"
        image: busybox
        imagePullPolicy: IfNotPresent
        name: busybox
        volumeMounts:
        - mountPath: /source/data
          name: source-data
      restartPolicy: Always
      volumes:
      - name: source-data
        configMap:
          name: stash-sample-data


Now, based on the following intent, generate the corresponding Kubernetes deployment configuration:

Intent: Deploy a scalable k8sdemo application with configurable replicas, image details, and resource requirements. The deployment uses a specified service account, implements security contexts, and configures liveness and readiness probes for health checks. It also supports advanced scheduling and resource management with optional node selectors, affinity, and tolerations. The deployment ensures controlled image pulling and maintains the specified container and pod settings for robust operation.

Configuration:
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8sdemo
  namespace: k8s-test
  labels:
    app: k8sdemo
  annotations:
    # This annotation ensures that the deployment will restore data from a previously backed up state on each restart of the workload
    stash.appscode.com/restorepolicy: "OnRestart"
    # Configure the backup repository and directories to be restored
    stash.appscode.com/repository: "k8s-backup-repo"
    stash.appscode.com/directories: "[/source/data]"
spec:
  replicas: 5 # The number of replicas to run
  selector:
    matchLabels:
      app: k8sdemo
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1 # Maximum number of instances that can be unavailable during the update
      maxSurge: 2 # Maximum number of new instances to deploy at once
  minReadySeconds: 30 # Minimum number of seconds for the pod to be ready before it can be considered available by the deployment controller
  serviceAccountName: k8s-service-account # The service account to use for this deployment
  template:
    metadata:
      labels:
        app: k8sdemo
        rolling-update: enabled
      name: k8sdemo
      # The following annotations configure pod security
      annotations:
        security.alpha.kubernetes.io/running-as-root: "false"
        security.alpha.kubernetes.io/seccomp-profile: "runtime/default"
    spec:
      serviceAccount: k8s-service-account # Reference the service account
      terminationGracePeriodSeconds: 5
      containers:
        - name: k8sdemo
          image: 637423476845.dkr.ecr.ap-south-1.amazonaws.com/k8simage:latest
          imagePullPolicy: IfNotPresent
          ports:
            - name: appPort
              containerPort: 8080 # Container port to be exposed
          env:
            - name: APP_CONFIG_FILE
              value: /app/config.yaml # Path to the configuration file inside the container
            - name: APP_ENV
              value: production # Application environment
          readinessProbe:
            httpGet:
              path: /healthz
              port: appPort
            initialDelaySeconds: 5
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /healthz
              port: appPort
            initialDelaySeconds: 5
            periodSeconds: 5
      securityContext:
        runAsUser: 1001
        runAsGroup: 3000
        fsGroup: 3000
      nodeSelector:
        zone: us-east-1a # Select specific node(s) for deployment based on the zone
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: tier
                operator: In
                values:
                - high
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: tier
                    operator: In
                    values:
                    - high
                topologyKey: failure-domain.beta.kubernetes.io/zone
                preferredDuringSchedulingIgnoredDuringExecution:
                  preferFailureDomainMatchExpressions:
                  - key: failure-domain.beta.kubernetes.io/zone
                    operator: In
                    values:
                    - us-east-1b
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 30
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: deployer
                  operator: In
                  values:
                  - deployer-1
              topologyKey: kubernetes.io/host
          requiredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: deployer
                  operator: In
                  values:
                  - deployer-1
              topologyKey: kubernetes.io/host
      tolerations:
        - operator: Exists
          effect: NoSchedule
          tolerationsSeconds: 300
        - operator: Exists
          effect: PreferNoSchedule
          tolerationsSeconds: 300
```
This Kubernetes deployment configuration deploys a scalable "k8sdemo" application with 5 replicas, using the specified "k8s-service-account" service account and configuring various options such as liveness and readiness probes, resource limits, security contexts, node selectors, and tolerations. It also includes advanced scheduling options, like pod anti-affinity and preferred pod affinity, to manage where and how the pods are deployed.